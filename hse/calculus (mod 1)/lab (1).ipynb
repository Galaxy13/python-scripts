{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zgX_XoiI6F8j"
   },
   "source": [
    "# Numerical Differentiation\n",
    "\n",
    "As far as finding a derivative analytically is purely technical task, it is also useful tp be able to establish some numerical approximations of the derivative (to analyze the trend or the rate pf change of some real-life time series, e.g. currency exchange rate, etc.).\n",
    "\n",
    "Baring that in mind one usually can solve two separate tasks: \n",
    "+ finding the derivative of a smooth function (assuming that the smoothness is given)\n",
    "+ finding the derivative of distorted function (e.g. a signal with some random noise)\n",
    "\n",
    "We propose you to try yourself in both tasks following our instructions.\n",
    "\n",
    "## Derivative of smooth functions: Finite Differences\n",
    "\n",
    "Assume that we have some nice smooth function $f(x)$ on a segment $I$. \n",
    "\n",
    "The simplest attempt to find the derivative stems from the definition of the derivative:\n",
    "$$    \n",
    "\\lim\\limits_{h \\to 0} \\frac{f(a+h)-f(a)}{h}=f'(a) \n",
    "$$\n",
    "\n",
    "Thus we can come up with an idea of the approximation:\n",
    "$$    \n",
    "f'(a)\\approx \\frac{f(a+h)-f(a)}{h}\n",
    "$$\n",
    "This formula is called **forward differences**.\n",
    "\n",
    "### Task 1. Forward differences implementation\n",
    "\n",
    "Let us start with basic imports: we start with `numpy` and `math` to work with arrays and mathematical functions (for `numpy` introduction and playground you can refer to the last week of our course or your Python course):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrmzUCpP6F8m"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QfkOLaLOc1Zc"
   },
   "source": [
    "Also we import and setup a couple of plotting libraries to make life prettier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TlHaY3eQ6F8z"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"notebook\", font_scale=2.0, rc={\"lines.linewidth\": 4.0})\n",
    "sns.set_palette('cubehelix')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BV3q13sSdRPR"
   },
   "source": [
    "You need to write a function with the following signature:\n",
    "```\n",
    "def derForward(f, I, h) \n",
    "```\n",
    "This function should get as input function $f$ and segment $I$ as Python list of two elements --- ends of the segment. \n",
    "\n",
    "In the function you are asked to divide the segment $I$ into small segments of length $h$, thus getting a grid $x$. Your function should return `dy` --- forward differences for each point `x` (except the border since the formula asks for the next value). You should return both `x` and `dy` arrays of the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qbz4vQuYdPJD"
   },
   "outputs": [],
   "source": [
    "def derForward(f, I, h):\n",
    "    # your code goes here\n",
    "    x=np.arange(I[0], I[1], h)\n",
    "    y=...\n",
    "    dy=...\n",
    "    x=...\n",
    "    return x, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get automatic basic check of your function (do not change it!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "J2tRPyJlkTto",
    "outputId": "2b4a8a7c-ad30-4ea9-c2f2-0de247a72bcb"
   },
   "outputs": [],
   "source": [
    "import checkerpub\n",
    "checkerpub.findif_check(derForward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOMXU_iKkdSW"
   },
   "source": [
    "### Task 2. Backward differences\n",
    "\n",
    "Similarly to forward differences, one can formulate **backward differences**:\n",
    "$$\n",
    "f'(a)\\approx \\frac{f(a)-f(a-h)}{h}\n",
    "$$\n",
    "\n",
    "Modify your function to get backward differences. **Note: your `x` should be different since now you ask for previous point!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derBackward(f, I, h):\n",
    "    # your code goes here\n",
    "    x=np.arange(I[0], I[1], h)\n",
    "    y=...\n",
    "    dy=...\n",
    "    x=...\n",
    "    return x, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get automatic basic check of your function (do not change it!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkerpub.findif_check(derBackward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Symmetrical Differences\n",
    "\n",
    "Essentially, one could try to bring forward/backward asymmetry together. This method is called **symmetrical differences**:\n",
    "$$\n",
    "f'(a) \\approx \\frac{f(a+h)-f(a-h)}{2h}\n",
    "$$\n",
    "Despite the fact we lose two poins now, let us also implement this method (we compare them below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derSymmetrical(f, I, h):\n",
    "    # your code goes here\n",
    "    x=np.arange(I[0], I[1], h)\n",
    "    y=...\n",
    "    dy=...\n",
    "    x=...\n",
    "    return x, dy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get automatic basic check of your function (do not change it!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkerpub.findif_check(derSymmetrical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Have you noticed that errors changed?** Let us illustrate it.\n",
    "\n",
    "## Task 4. Compare by eyes\n",
    "\n",
    "Assume we want to experiment with $f(x)=\\sin(x)$. Let $I=[0, 2\\pi]$ and $h=1/10$. Compute:\n",
    "+ forward differences\n",
    "+ backward differences\n",
    "+ symmetrical differences\n",
    "\n",
    "If we plot all results with the right answer ($f'(x)=\\cos(x)$), we should get picture like this:\n",
    "\n",
    "![target](tmp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 718
    },
    "colab_type": "code",
    "id": "w3EOBXNO6F84",
    "outputId": "cc89e196-b8ac-4a33-f7c6-a4e8726ca5dd"
   },
   "outputs": [],
   "source": [
    "plt.subplots(1, 2, figsize=(20,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x, np.cos(x), 'b-')\n",
    "\n",
    "# your code goes here\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(x[:10], np.cos(x)[:10], 'b-', label='Real answer')\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we have seen by tests above, symmetrical differences are the most accurate.** You can also experiment with $f(x)=x^x$ below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Cq2QpHxAAKB"
   },
   "source": [
    "## Task 5. Error estimation\n",
    "\n",
    "Using **Taylor expansion**, one can show the following estimations:\n",
    "\n",
    "1) $ \\left| \\frac{f(a+h)-f(a)}{h} -f'(a) \\right| \\le \\frac{h}{2}M  $\n",
    "where $M=\\max_{x\\in[a;a+h]} f''(x)$;\n",
    "\n",
    "2) $ \\left| \\frac{f(a)-f(a-h)}{h} -f'(a) \\right| \\le \\frac{h}{2}M  $\n",
    "where $M=\\max_{x\\in[a;a+h]} f''(x)$;\n",
    "\n",
    "3) $ \\left| \\frac{f(a+h)-f(a-h)}{2h} -f'(a) \\right| \\le \\frac{h^2}{6}M  $\n",
    "where $M=\\max_{x\\in[a;a+h]} f'''(x)$;\n",
    "\n",
    "This is a point-wise estimations, so we will use the maximal of then on the whole segment:\n",
    "$$\n",
    "\\left| \\frac{f(a+h)-f(a)}{h} -f'(a) \\right| \\to \\max_{a\\in I} \\left| \\frac{f(a+h)-f(a)}{h} -f'(a) \\right|=Err(h)\n",
    "$$\n",
    "\n",
    "For different values of $h$ estimate errors for **forward** and **symmetrical** differences (use $f(x)=\\sin(x)$):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ce7TaGq66F89"
   },
   "outputs": [],
   "source": [
    "hs=np.array([1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001])\n",
    "errs_forward=[]\n",
    "errs_symmetrical=[]\n",
    "\n",
    "for h in hs:\n",
    "    # your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKWyGpMHBVEz"
   },
   "source": [
    "Since we want to show that:\n",
    "$$\n",
    "Err(h) \\sim h^\\gamma\n",
    "$$\n",
    "it is essential to use `loglog` scale: if you take logarithm from both sides, you get:\n",
    "$$ \\ln Err(h) \\sim \\gamma \\ln h $$\n",
    "a straight line. Acquiring $\\gamma$ is negative, it is better to plot it against not $h$, but $1/h$ or $|I|/h$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "ZtfB0HllCyNs",
    "outputId": "21ae634a-218b-4009-ddfe-21229388c5ca"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "#your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6. Derivative of Noised function\n",
    "\n",
    "Assume that we got somehow noised $\\sin(x)$ function from real-life source, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, data=checkerpub.getNoised(n=1000, alpha=0.1, sigma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6cWC5WoVxOJ"
   },
   "source": [
    "Here:\n",
    "+ `n` is a number of points on the $[0, 10]$ segment;\n",
    "+ `alpha` is a parameter of autoregression; in a way, it refers to the memory of the noise -- how long it \"remembers\" distorted values; if this parameter is close to $1$, function will sufficiently diverge from the initial $\\sin(x)$;\n",
    "+ `sigma` is the dispersion of the noise.\n",
    "\n",
    "Let us plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "colab_type": "code",
    "id": "6RRSXIkQWNmJ",
    "outputId": "b77214b6-6c02-4abc-f3fd-4f9e16014e5e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(x, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to apply finite differences to this function. The result will be catastrophically large due to the noise: our function stopped being smooth. Hence, we need more stable mechanism of finding a derivative.\n",
    "\n",
    "The idea is the following:\n",
    "\n",
    "1. By the definition of differentiability, differentiable function can be approximated by piecewise-linear;\n",
    "\n",
    "2. Assume we have this approximation. If we consider some heighbourhood of the given point $a$, then the approximation is not _piecewise linear_ --- it is just linear! And it is easy to differentiate linear function.\n",
    "\n",
    "Formally one should do the following: \n",
    "\n",
    "+ we characterize the neightbourhood by half-window length `hw`, thus for the `i`-point in array we are considering `[i-hw:i+hw]` window\n",
    "\n",
    "+ in such a window one should find the closest approximating line and determine its coefficient; it's an approximation of the derivative\n",
    "\n",
    "**Note**: you do not need the knowledge of the formula of the coefficient: since we stated here `Linear Regression` problem, you can use already written one\n",
    "\n",
    "**Note**: you can always choose not to use it, so we write the formula here:\n",
    "$$\n",
    "\\kappa=\\frac{n \\sum_{i=1}^n (x_iy_i)-\\left( \\sum_{i=1}^n x_i \\right)\\left( \\sum_{i=1}^n y_i \\right)}{n\\sum_{i=1}^n x^2_i-\\left( \\sum_{i=1}^n x_i \\right)^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derWindow(x, y, hw):\n",
    "    # your code goes here\n",
    "\n",
    "    return x, df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to check ourselves. If we choose smooth enough function (e.g. $\\sin x$) then our sliding derivative technique should be close to real derivative (with reasonable `hw`). Check your function for different `hw`; you may also change $\\sin x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.linspace(0, 2*np.pi, 10000)\n",
    "hw=...\n",
    "y_test=np.sin(x_test)\n",
    "\n",
    "der_true=np.cos(x_test)\n",
    "\n",
    "x_new, der_new=derWindow(x_test, y_test, hw)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(x_test, der_true, 'b-', linewidth=4, alpha=0.3)\n",
    "plt.plot(x_new, dernew, 'r-', linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4iGtpNzcWy68"
   },
   "source": [
    "### Task 7. Plot results\n",
    "\n",
    "Let us also plot results for three different half-window sizes: 50, 10 and 200.\n",
    "    \n",
    "**PLease, try to use different colors and styles to make a nice picture!** You should get something close to:\n",
    "\n",
    "![](tmp2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "EgLTCIU5ZGsX",
    "outputId": "54f63e67-d601-4be0-ddb0-8ad234e64cd2"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(x, data, alpha=0.2)\n",
    "plt.plot(x, np.cos(x), 'b')\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgnB12UiZNko"
   },
   "source": [
    "It is also interesting to play with different `alpha` and `sigma`. You are welcome to do it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8. Results\n",
    "\n",
    "Please, answer the following questions:\n",
    "\n",
    "1. Does theoretical estimations of the error coincide with your experiments? If there is a divergence from a straight line, how can it be explained?\n",
    "\n",
    "2. What can you say about optimal window length in the last part of the experiment? Is there any monotonic behaviour?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "2."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Numerical_Differentiation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
